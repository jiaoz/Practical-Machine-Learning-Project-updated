---
title: "PracticalMachineLearning"
author: "JiaoZhang"
date: "March 19, 2016"
output: html_document
---

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
#read data
training<- read.csv("C:/R/pml-training.csv",header=TRUE)
testing<- read.csv("C:/R/pml-testing.csv",header=TRUE)
#load packages
library(ISLR);library(ggplot2);library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
summary(training)
#Partioning Training data set into two data sets, 60% for Train, 40% for Test
inTrain<-createDataPartition(y=training$classe,p=0.6,list=FALSE)
Train<-training[inTrain,]
Test<-training[-inTrain,]
dim(Train); dim(Test)
# cleaning the data
myDataNZV <- nearZeroVar(Train, saveMetrics=TRUE)
str(myDataNZV)
myDataNZV [myDataNZV [,"zeroVar"] + myDataNZV [,"nzv"] > 0, ]
myNZVvars <- names(Train) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
                                      "kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
                                      "max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
                                      "var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
                                      "stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
                                      "kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
                                      "max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
                                      "kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
                                      "skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
                                      "amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
                                      "skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
                                      "max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
                                      "amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
                                      "avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
                                      "stddev_yaw_forearm", "var_yaw_forearm")
Train <- Train[!myNZVvars]
dim(Train)
# eliminate the first id column
Train <- Train[c(-1)]
#: Cleaning Variables with too many NAs. For Variables that have more than a 60% threshold of NA's I'm going to leave them out
Train2  <- Train #creating another subset to iterate in loop
for(i in 1:length(Train)) { #for every column in the training dataset
    if( sum( is.na( Train [, i] ) ) /nrow(Train ) >= .6 ) { #if n?? NAs > 60% of total observations
        for(j in 1:length(Train2)) {
            if( length( grep(names(Train[i]), names(Train2)[j]) ) ==1)  { #if the columns are the same:
                Train2 <- Train2[ , -j] #Remove that column
            }   
        } 
    }
}
#To check the new N?? of observations
dim(Train2)
#Now let us do the exact same 3 transformations but for our myTesting and testing data sets.

clean1 <- colnames(Train2)
clean2 <- colnames(Train2[, -58]) #already with classe column removed
Test <- Test[clean1]
dim(Train2)
dim(Test)
testing <- testing[clean2]
dim(testing)


for (i in 1:length(testing) ) {
    for(j in 1:length(Train2)) {
        if( length( grep(names(Train2[i]), names(testing)[j]) ) ==1)  {
            class(testing[j]) <- class(Train2[i])
        }      
    }      
}
#And to make sure Coertion really worked, simple smart ass technique:
testing <- rbind(Train2[2, -58] , testing) 
testing <- testing[-1,]
# Decision tree
modFit_DecisionTree<-rpart(classe~.,data=Train2,method="class")
fancyRpartPlot(modFit_DecisionTree)
predict_DecisionTree<- predict(modFit_DecisionTree,Test,type="class")
confusionMatrix(predict_DecisionTree,Test$classe)
# random forest
modFit_RandomForest<- randomForest(classe~.,data=Train2)
prediction_RandomForest<-predict(modFit_RandomForest,Test,type="class")
confusionMatrix(prediction_RandomForest,Test$classe)
# leave out sample testing
predition_out<-predict(modFit_RandomForest,testing,type="class")

pml_write_files = function(x){
    n = length(x)
    for(i in 1:n){
        filename = paste0("problem_id_",i,".txt")
        write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
    }
}

pml_write_files(predition_out)
predition_out
```



Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
